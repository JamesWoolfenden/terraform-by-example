{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Terraform-by-example Terraform 101 From Zero. By James Woolfenden I've been using Terraform since version 0.5 https://www.hashicorp.com/blog/terraform-0-5/ while that seems a while, I'm still learning and it's still changing. I've used it with all of the main public clouds. The majority of the examples here will target AWS, but no prior knowledge is required. Pre-requisites Terraform 0.12.21 or newer. An editor, VSCode, Atom or equivalent. Resources This site https://jameswoolfenden.github.io/terraform-by-example/ This repo: https://github.com/JamesWoolfenden/terraform-by-example/ Further work: https://jameswoolfenden.github.io/learn-terraform/ Hashicorps learn site https://learn.hashicorp.com/terraform Note These lessons are aimed at anyone, only familiarity with Git and a code editor [atom or VSCode] is expected. Terraform can be a real handful to type at the CLI , but at least its not called * constellation * as originally planned .","title":"Home"},{"location":"#terraform-by-example","text":"","title":"Terraform-by-example"},{"location":"#terraform-101","text":"From Zero. By James Woolfenden I've been using Terraform since version 0.5 https://www.hashicorp.com/blog/terraform-0-5/ while that seems a while, I'm still learning and it's still changing. I've used it with all of the main public clouds. The majority of the examples here will target AWS, but no prior knowledge is required.","title":"Terraform 101"},{"location":"#pre-requisites","text":"Terraform 0.12.21 or newer. An editor, VSCode, Atom or equivalent.","title":"Pre-requisites"},{"location":"#resources","text":"This site https://jameswoolfenden.github.io/terraform-by-example/ This repo: https://github.com/JamesWoolfenden/terraform-by-example/ Further work: https://jameswoolfenden.github.io/learn-terraform/ Hashicorps learn site https://learn.hashicorp.com/terraform Note These lessons are aimed at anyone, only familiarity with Git and a code editor [atom or VSCode] is expected. Terraform can be a real handful to type at the CLI , but at least its not called * constellation * as originally planned .","title":"Resources"},{"location":"about/","text":"About Author: James Woolfenden LinkedIn Bio I'm currently working as a Principal for Slalom and based out of London. I have a bit of experience in the DevOps field, I have worked for a number of consultancies directly and indirectly. This is the second of series on Learning about DevOps. Why This is small run through of using Hashicorp Terraform. As a consultant I frequently have to train developers and \"DevOps\" Engineers how, why and when to use it. I started using Terraform from around version 0.5, I was on a Greenfield AWS project and was really struggling with Cloudformation and its tooling. I asked a question on Linkedin on what others were using and the steers I got were Terraform or Ansible. I achieved more in the day after than in the previous week. Hopefully you'll find this book useful. If it's missing or wrong in anyway, log an Issue or even submit a PR. Each Chapter also contains a copy of the code the chapter tries to teach you how to create. I originally wrote this for the pre 0.11 Terraform and I hopefully updated everything to 0.12 and all the samples should work.","title":"About"},{"location":"about/#about","text":"","title":"About"},{"location":"about/#author-james-woolfenden","text":"LinkedIn","title":"Author: James Woolfenden"},{"location":"about/#bio","text":"I'm currently working as a Principal for Slalom and based out of London. I have a bit of experience in the DevOps field, I have worked for a number of consultancies directly and indirectly. This is the second of series on Learning about DevOps.","title":"Bio"},{"location":"about/#why","text":"This is small run through of using Hashicorp Terraform. As a consultant I frequently have to train developers and \"DevOps\" Engineers how, why and when to use it. I started using Terraform from around version 0.5, I was on a Greenfield AWS project and was really struggling with Cloudformation and its tooling. I asked a question on Linkedin on what others were using and the steers I got were Terraform or Ansible. I achieved more in the day after than in the previous week. Hopefully you'll find this book useful. If it's missing or wrong in anyway, log an Issue or even submit a PR. Each Chapter also contains a copy of the code the chapter tries to teach you how to create. I originally wrote this for the pre 0.11 Terraform and I hopefully updated everything to 0.12 and all the samples should work.","title":"Why"},{"location":"help/","text":"Help If its been useful, let me know. If it out of date or broken also. I'll appreciate it. Or If you think something's missing or contribute? Got a question? File a GitHub issue . Contributing Bug Reports & Feature Requests Please use the issue tracker to report any bugs or file feature requests. Copyrights Copyright (c) 2019-2021 James Woolfenden License Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements. See the NOTICE file distributed with this work for additional information regarding copyright ownership. The ASF licenses this file to you under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at https://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. Contributors James Woolfenden","title":"Help"},{"location":"help/#help","text":"If its been useful, let me know. If it out of date or broken also. I'll appreciate it. Or If you think something's missing or contribute? Got a question? File a GitHub issue .","title":"Help"},{"location":"help/#contributing","text":"","title":"Contributing"},{"location":"help/#bug-reports-feature-requests","text":"Please use the issue tracker to report any bugs or file feature requests.","title":"Bug Reports &amp; Feature Requests"},{"location":"help/#copyrights","text":"Copyright (c) 2019-2021 James Woolfenden","title":"Copyrights"},{"location":"help/#license","text":"Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements. See the NOTICE file distributed with this work for additional information regarding copyright ownership. The ASF licenses this file to you under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at https://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.","title":"License"},{"location":"help/#contributors","text":"James Woolfenden","title":"Contributors"},{"location":"lesson1/","text":"Lesson 101 Hello World my first template To start, make a null resource by creating a file called null_resource.helloworld.tf . A null resource doesn't do anything by itself. touch null_resource.helloworld.tf Then add the block below to it. resource \"null_resource\" \"hello_world\" { } You have created your first Terraform template, but as yet it does nothing. Adding a local executable provisioner to give the null resource some utility: resource \"null_resource\" \"hello_world\" { provisioner \"local-exec\" { # This is a comment command = \"echo 'hello world'\" } } Time to try your work with terraform init . $ terraform init Initializing the backend... Initializing provider plugins... - Checking for available provider plugins... - Downloading plugin for provider \"null\" ( hashicorp/null ) 2 .1.2... The following providers do not have any version constraints in configuration, so the latest version was installed. To prevent automatic upgrades to new major versions that may contain breaking changes, it is recommended to add version = \"...\" constraints to the corresponding provider blocks in configuration, with the constraint strings suggested below. * provider.null: version = \"~> 2.1\" Terraform has been successfully initialized! You may now begin working with Terraform. Try running \"terraform plan\" to see any changes that are required for your infrastructure. All Terraform commands should now work. If you ever set or change modules or backend configuration for Terraform, rerun this command to reinitialize your working directory. If you forget, other commands will detect it and remind you to do so if necessary. Terraform init is only needed on new templates and when you add modules or change module versions or providers. You don't have to remember it all, Terraform will fail at apply. Now that has been set up, you can try terraform apply , and when prompted, say yes. $ terraform apply An execution plan has been generated and is shown below. Resource actions are indicated with the following symbols: + create Terraform will perform the following actions: # null_resource.hello_world will be created + resource \"null_resource\" \"hello_world\" { + id = ( known after apply ) } Plan: 1 to add, 0 to change, 0 to destroy. Do you want to perform these actions? Terraform will perform the actions described above. Only 'yes' will be accepted to approve. Enter a value: yes null_resource.hello_world: Creating... null_resource.hello_world: Provisioning with 'local-exec' ... null_resource.hello_world ( local-exec ) : Executing: [ \"cmd\" \"/C\" \"echo 'hello world'\" ] null_resource.hello_world ( local-exec ) : 'hello world' null_resource.hello_world: Creation complete after 1s [ id = 5019739039794330655 ] Apply complete! Resources: 1 added, 0 changed, 0 destroyed. You have made a Terraform template that does something! Now check what files you have on your filesystem. ls -al total 1 drwxrwxrwx 1 jim jim 512 Feb 22 06 :59 . drwxrwxrwx 1 jim jim 512 Feb 22 06 :54 .. drwxrwxrwx 1 jim jim 512 Feb 22 06 :56 .terraform -rwxrwxrwx 1 jim jim 139 Feb 22 06 :59 null.helloworld.tf -rwxrwxrwx 1 jim jim 513 Feb 22 06 :59 terraform.tfstate Terraform.tfstate is your local state file .terraform contains your providers and modules[if any]. Refactor Specify the exact Provider version required provider.null.tf provider \"null\" { version = \"2.1.2\" } We specify versions so that we reproduce the same result. Specify the TF core version by specifying Terraform version in terraform.tf terraform { required_version = \"0.12.20\" } State files are linked to TF core version, all members of a team using TF need to use the same version. If one upgrades, all must upgrade, so add this to ensure that you mean to. Re-test these changes with a new apply. Real world example resource \"null_resource\" \"waiter\" { depends_on = [ aws_iam_instance_profile . ec 2 profile ] provisioner \"local-exec\" { command = \"sleep 15\" } } This is basically a hack, pretty much any use of a null resources is up to something dubious. In this case AWS was being rubbish and reported that an object was made when it wasn't yet - eventually consistent and so here we are with a sleep statement. I rarely use Provisioners myself these days, they are bad style and a hangover from Terraforms beginnings. Takeaways Naming Versions Provisioners Providers Plan & apply Exercise Change the required_version to \"0.12.25\" and Apply, what happens? Questions Documentation For more on null resource see the Hashicorp docs: https://www.terraform.io/docs/providers/null/resource.html","title":"Lesson 101"},{"location":"lesson1/#lesson-101-hello-world","text":"","title":"Lesson 101 Hello World"},{"location":"lesson1/#my-first-template","text":"To start, make a null resource by creating a file called null_resource.helloworld.tf . A null resource doesn't do anything by itself. touch null_resource.helloworld.tf Then add the block below to it. resource \"null_resource\" \"hello_world\" { } You have created your first Terraform template, but as yet it does nothing. Adding a local executable provisioner to give the null resource some utility: resource \"null_resource\" \"hello_world\" { provisioner \"local-exec\" { # This is a comment command = \"echo 'hello world'\" } } Time to try your work with terraform init . $ terraform init Initializing the backend... Initializing provider plugins... - Checking for available provider plugins... - Downloading plugin for provider \"null\" ( hashicorp/null ) 2 .1.2... The following providers do not have any version constraints in configuration, so the latest version was installed. To prevent automatic upgrades to new major versions that may contain breaking changes, it is recommended to add version = \"...\" constraints to the corresponding provider blocks in configuration, with the constraint strings suggested below. * provider.null: version = \"~> 2.1\" Terraform has been successfully initialized! You may now begin working with Terraform. Try running \"terraform plan\" to see any changes that are required for your infrastructure. All Terraform commands should now work. If you ever set or change modules or backend configuration for Terraform, rerun this command to reinitialize your working directory. If you forget, other commands will detect it and remind you to do so if necessary. Terraform init is only needed on new templates and when you add modules or change module versions or providers. You don't have to remember it all, Terraform will fail at apply. Now that has been set up, you can try terraform apply , and when prompted, say yes. $ terraform apply An execution plan has been generated and is shown below. Resource actions are indicated with the following symbols: + create Terraform will perform the following actions: # null_resource.hello_world will be created + resource \"null_resource\" \"hello_world\" { + id = ( known after apply ) } Plan: 1 to add, 0 to change, 0 to destroy. Do you want to perform these actions? Terraform will perform the actions described above. Only 'yes' will be accepted to approve. Enter a value: yes null_resource.hello_world: Creating... null_resource.hello_world: Provisioning with 'local-exec' ... null_resource.hello_world ( local-exec ) : Executing: [ \"cmd\" \"/C\" \"echo 'hello world'\" ] null_resource.hello_world ( local-exec ) : 'hello world' null_resource.hello_world: Creation complete after 1s [ id = 5019739039794330655 ] Apply complete! Resources: 1 added, 0 changed, 0 destroyed. You have made a Terraform template that does something! Now check what files you have on your filesystem. ls -al total 1 drwxrwxrwx 1 jim jim 512 Feb 22 06 :59 . drwxrwxrwx 1 jim jim 512 Feb 22 06 :54 .. drwxrwxrwx 1 jim jim 512 Feb 22 06 :56 .terraform -rwxrwxrwx 1 jim jim 139 Feb 22 06 :59 null.helloworld.tf -rwxrwxrwx 1 jim jim 513 Feb 22 06 :59 terraform.tfstate Terraform.tfstate is your local state file .terraform contains your providers and modules[if any].","title":"my first template"},{"location":"lesson1/#refactor","text":"Specify the exact Provider version required provider.null.tf provider \"null\" { version = \"2.1.2\" } We specify versions so that we reproduce the same result. Specify the TF core version by specifying Terraform version in terraform.tf terraform { required_version = \"0.12.20\" } State files are linked to TF core version, all members of a team using TF need to use the same version. If one upgrades, all must upgrade, so add this to ensure that you mean to. Re-test these changes with a new apply.","title":"Refactor"},{"location":"lesson1/#real-world-example","text":"resource \"null_resource\" \"waiter\" { depends_on = [ aws_iam_instance_profile . ec 2 profile ] provisioner \"local-exec\" { command = \"sleep 15\" } } This is basically a hack, pretty much any use of a null resources is up to something dubious. In this case AWS was being rubbish and reported that an object was made when it wasn't yet - eventually consistent and so here we are with a sleep statement. I rarely use Provisioners myself these days, they are bad style and a hangover from Terraforms beginnings. Takeaways Naming Versions Provisioners Providers Plan & apply","title":"Real world example"},{"location":"lesson1/#exercise","text":"Change the required_version to \"0.12.25\" and Apply, what happens?","title":"Exercise"},{"location":"lesson1/#questions","text":"","title":"Questions"},{"location":"lesson1/#documentation","text":"For more on null resource see the Hashicorp docs: https://www.terraform.io/docs/providers/null/resource.html","title":"Documentation"},{"location":"lesson10/","text":"Lesson 8 Refactor Using the lessons from earlier refactor this chapter. Takeaways take this Exercises Questions Documentation","title":"Lesson 203"},{"location":"lesson10/#lesson-8","text":"","title":"Lesson 8"},{"location":"lesson10/#refactor","text":"Using the lessons from earlier refactor this chapter. Takeaways take this","title":"Refactor"},{"location":"lesson10/#exercises","text":"","title":"Exercises"},{"location":"lesson10/#questions","text":"","title":"Questions"},{"location":"lesson10/#documentation","text":"","title":"Documentation"},{"location":"lesson11/","text":"Lesson 8 Refactor Using the lessons from earlier refactor this chapter. Takeaways take this Exercises Questions Documentation","title":"Lesson 204"},{"location":"lesson11/#lesson-8","text":"","title":"Lesson 8"},{"location":"lesson11/#refactor","text":"Using the lessons from earlier refactor this chapter. Takeaways take this","title":"Refactor"},{"location":"lesson11/#exercises","text":"","title":"Exercises"},{"location":"lesson11/#questions","text":"","title":"Questions"},{"location":"lesson11/#documentation","text":"","title":"Documentation"},{"location":"lesson12/","text":"Lesson 8 Refactor Using the lessons from earlier refactor this chapter. Takeaways take this Exercises Questions Documentation","title":"Lesson 205"},{"location":"lesson12/#lesson-8","text":"","title":"Lesson 8"},{"location":"lesson12/#refactor","text":"Using the lessons from earlier refactor this chapter. Takeaways take this","title":"Refactor"},{"location":"lesson12/#exercises","text":"","title":"Exercises"},{"location":"lesson12/#questions","text":"","title":"Questions"},{"location":"lesson12/#documentation","text":"","title":"Documentation"},{"location":"lesson13/","text":"Lesson 8 Refactor Using the lessons from earlier refactor this chapter. Takeaways take this Exercises Questions Documentation","title":"Lesson 206"},{"location":"lesson13/#lesson-8","text":"","title":"Lesson 8"},{"location":"lesson13/#refactor","text":"Using the lessons from earlier refactor this chapter. Takeaways take this","title":"Refactor"},{"location":"lesson13/#exercises","text":"","title":"Exercises"},{"location":"lesson13/#questions","text":"","title":"Questions"},{"location":"lesson13/#documentation","text":"","title":"Documentation"},{"location":"lesson14/","text":"Lesson 8 Refactor Using the lessons from earlier refactor this chapter. Takeaways take this Exercises Questions Documentation","title":"Lesson 207"},{"location":"lesson14/#lesson-8","text":"","title":"Lesson 8"},{"location":"lesson14/#refactor","text":"Using the lessons from earlier refactor this chapter. Takeaways take this","title":"Refactor"},{"location":"lesson14/#exercises","text":"","title":"Exercises"},{"location":"lesson14/#questions","text":"","title":"Questions"},{"location":"lesson14/#documentation","text":"","title":"Documentation"},{"location":"lesson2/","text":"Lesson 102 Variables Variables We are going to modify the lesson 1 code to use a variable, adding in \"from ${var.user}\". resource \"null_resource\" \"hello_world\" { provisioner \"local-exec\" { # This is a comment command = \"echo 'hello world from ${var.user}'\" } } You don't need to run Terraform init as there's been no change to providers or modules, so it's straight to using apply. $terraform apply Error: Reference to undeclared input variable on null_resource.helloworld.tf line 4 , in resource \"null_resource\" \"hello_world\" : 4 : command = \"echo 'hello world from ${ var .user } '\" An input variable with the name \"user\" has not been declared. This variable can be declared with a variable \"user\" {} block. That didn't work. You need to declare the variable user , you could just add the block below to any Terraform file, but the correct way is to add a file called variables.tf and use that. This is a convention. variable \"user\" { type = string } And apply. $ terraform apply var.user Enter a value: You could work with Terraform like this, and type in the values each time it runs. Thankfully, there are other options. Defaults Modify your variable declaration to have a default value. variable \"user\" { type = string default = \"DEFAULT\" } Overrides terraform apply -var \"user=SHELL\" What happened? terraform apply -var 'user=SHELL' null_resource.hello_world: Refreshing state... [ id = 5019739039794330655 ] Apply complete! Resources: 0 added, 0 changed, 0 destroyed. What should have happened? Hopefully a different output showing the new value, so why didn't it? This is because you're using a shell command in a null resource there is no state record. Check your state file terraform.tfstate { \"version\" : 4 , \"terraform_version\" : \"0.12.20\" , \"serial\" : 10 , \"lineage\" : \"10c120f2-386d-3c02-5395-9b2b9e26c5ec\" , \"outputs\" : {}, \"resources\" : [ { \"mode\" : \"managed\" , \"type\" : \"null_resource\" , \"name\" : \"hello_world\" , \"provider\" : \"provider.null\" , \"instances\" : [ { \"schema_version\" : 0 , \"attributes\" : { \"id\" : \"1300466885639272531\" , \"triggers\" : null }, \"private\" : \"bnVsbA==\" } ] } ] } Destroy your template: $terraform destroy null_resource.hello_world: Refreshing state... [ id = 7244294109451146186 ] An execution plan has been generated and is shown below. Resource actions are indicated with the following symbols: - destroy Terraform will perform the following actions: # null_resource.hello_world will be destroyed - resource \"null_resource\" \"hello_world\" { - id = \"7244294109451146186\" -> null } Plan: 0 to add, 0 to change, 1 to destroy. Do you really want to destroy all resources? Terraform will destroy all your managed infrastructure, as shown above. There is no undo. Only 'yes' will be accepted to confirm. Enter a value: yes null_resource.hello_world: Destroying... [ id = 7244294109451146186 ] null_resource.hello_world: Destruction complete after 0s ``` Now try supplying value again and it will work: $ terraform apply -var 'user=SHELL' An execution plan has been generated and is shown below. Resource actions are indicated with the following symbols: + create Terraform will perform the following actions: # null_resource.hello_world will be created + resource \"null_resource\" \"hello_world\" { + id = ( known after apply ) } Plan: 1 to add, 0 to change, 0 to destroy. Do you want to perform these actions? Terraform will perform the actions described above. Only 'yes' will be accepted to approve. Enter a value: yes null_resource.hello_world: Creating... null_resource.hello_world: Provisioning with 'local-exec' ... null_resource.hello_world ( local-exec ) : Executing: [ \"cmd\" \"/C\" \"echo 'hello world from SHELL'\" ] null_resource.hello_world ( local-exec ) : 'hello world from SHELL' null_resource.hello_world: Creation complete after 0s [ id = 4486592786807831720 ] Apply complete! Resources: 1 added, 0 changed, 0 destroyed. environmental variables Add an environmental variable to your shell call TF_VAR_user to your shell. export TF_VAR_user=\"environment\" or $env:TF_VAR_user=\"environment\" And apply. $ export TF_VAR_user = \"environment\" \u2714 /mnt/c/code/mkdocs/terraform-by-example/examples/lesson2 [ master L | \u20269 ] 09 :29 $ terraform apply An execution plan has been generated and is shown below. Resource actions are indicated with the following symbols: + create Terraform will perform the following actions: # null_resource.hello_world will be created + resource \"null_resource\" \"hello_world\" { + id = ( known after apply ) } Plan: 1 to add, 0 to change, 0 to destroy. Do you want to perform these actions? Terraform will perform the actions described above. Only 'yes' will be accepted to approve. Enter a value: So Terraform looks for the values of your variables as long as they have the prefix TF_VAR_ but there are exceptions. Tfvars Terraform can also take the values of variables from a tfvars file. Make sure to erase your environmental variables from the previous section. Add a file called guff.tfvars user = \"guff\" And apply. $ terraform apply var.user Enter a value: So that didn't work. There's a convention for variable files \"tfvars\", the old convention is to use a file called terraform.tfvars but you can now use multiple tfvar files as long as they have auto in their name. Rename guff.tfvars guff.auto.tfvars and re-apply. Outputs It's also good practice to include your outputs. This helps with debugging and making your template or module extendible. By convention it's called Outputs.tf output \"hello_world\" { description = \"The Output of the Null resource\" value = null_resource . hello_world } Now when you apply, you should see something like this at the end of your output; Apply complete! Resources: 1 added, 0 changed, 0 destroyed. Outputs: hello_world = { \"id\" = \"562214568453658147\" } Takeaways variables overrides syntax checking outputs defaults cli usage environmental variables tfvars state with null resource local execs are contents not infrastructure so there's no record in state Exercises What other data types can a variable be? Modify the example to use a list type. What other file formats are supported? Questions Documentation https://www.terraform.io/docs/configuration/syntax-json.html For more on variables see the Hashicorp docs: https://www.terraform.io/docs/configuration/variables.html","title":"Lesson 102"},{"location":"lesson2/#lesson-102-variables","text":"","title":"Lesson 102 Variables"},{"location":"lesson2/#variables","text":"We are going to modify the lesson 1 code to use a variable, adding in \"from ${var.user}\". resource \"null_resource\" \"hello_world\" { provisioner \"local-exec\" { # This is a comment command = \"echo 'hello world from ${var.user}'\" } } You don't need to run Terraform init as there's been no change to providers or modules, so it's straight to using apply. $terraform apply Error: Reference to undeclared input variable on null_resource.helloworld.tf line 4 , in resource \"null_resource\" \"hello_world\" : 4 : command = \"echo 'hello world from ${ var .user } '\" An input variable with the name \"user\" has not been declared. This variable can be declared with a variable \"user\" {} block. That didn't work. You need to declare the variable user , you could just add the block below to any Terraform file, but the correct way is to add a file called variables.tf and use that. This is a convention. variable \"user\" { type = string } And apply. $ terraform apply var.user Enter a value: You could work with Terraform like this, and type in the values each time it runs. Thankfully, there are other options.","title":"Variables"},{"location":"lesson2/#defaults","text":"Modify your variable declaration to have a default value. variable \"user\" { type = string default = \"DEFAULT\" }","title":"Defaults"},{"location":"lesson2/#overrides","text":"terraform apply -var \"user=SHELL\" What happened? terraform apply -var 'user=SHELL' null_resource.hello_world: Refreshing state... [ id = 5019739039794330655 ] Apply complete! Resources: 0 added, 0 changed, 0 destroyed. What should have happened? Hopefully a different output showing the new value, so why didn't it? This is because you're using a shell command in a null resource there is no state record. Check your state file terraform.tfstate { \"version\" : 4 , \"terraform_version\" : \"0.12.20\" , \"serial\" : 10 , \"lineage\" : \"10c120f2-386d-3c02-5395-9b2b9e26c5ec\" , \"outputs\" : {}, \"resources\" : [ { \"mode\" : \"managed\" , \"type\" : \"null_resource\" , \"name\" : \"hello_world\" , \"provider\" : \"provider.null\" , \"instances\" : [ { \"schema_version\" : 0 , \"attributes\" : { \"id\" : \"1300466885639272531\" , \"triggers\" : null }, \"private\" : \"bnVsbA==\" } ] } ] } Destroy your template: $terraform destroy null_resource.hello_world: Refreshing state... [ id = 7244294109451146186 ] An execution plan has been generated and is shown below. Resource actions are indicated with the following symbols: - destroy Terraform will perform the following actions: # null_resource.hello_world will be destroyed - resource \"null_resource\" \"hello_world\" { - id = \"7244294109451146186\" -> null } Plan: 0 to add, 0 to change, 1 to destroy. Do you really want to destroy all resources? Terraform will destroy all your managed infrastructure, as shown above. There is no undo. Only 'yes' will be accepted to confirm. Enter a value: yes null_resource.hello_world: Destroying... [ id = 7244294109451146186 ] null_resource.hello_world: Destruction complete after 0s ``` Now try supplying value again and it will work: $ terraform apply -var 'user=SHELL' An execution plan has been generated and is shown below. Resource actions are indicated with the following symbols: + create Terraform will perform the following actions: # null_resource.hello_world will be created + resource \"null_resource\" \"hello_world\" { + id = ( known after apply ) } Plan: 1 to add, 0 to change, 0 to destroy. Do you want to perform these actions? Terraform will perform the actions described above. Only 'yes' will be accepted to approve. Enter a value: yes null_resource.hello_world: Creating... null_resource.hello_world: Provisioning with 'local-exec' ... null_resource.hello_world ( local-exec ) : Executing: [ \"cmd\" \"/C\" \"echo 'hello world from SHELL'\" ] null_resource.hello_world ( local-exec ) : 'hello world from SHELL' null_resource.hello_world: Creation complete after 0s [ id = 4486592786807831720 ] Apply complete! Resources: 1 added, 0 changed, 0 destroyed.","title":"Overrides"},{"location":"lesson2/#environmental-variables","text":"Add an environmental variable to your shell call TF_VAR_user to your shell. export TF_VAR_user=\"environment\" or $env:TF_VAR_user=\"environment\" And apply. $ export TF_VAR_user = \"environment\" \u2714 /mnt/c/code/mkdocs/terraform-by-example/examples/lesson2 [ master L | \u20269 ] 09 :29 $ terraform apply An execution plan has been generated and is shown below. Resource actions are indicated with the following symbols: + create Terraform will perform the following actions: # null_resource.hello_world will be created + resource \"null_resource\" \"hello_world\" { + id = ( known after apply ) } Plan: 1 to add, 0 to change, 0 to destroy. Do you want to perform these actions? Terraform will perform the actions described above. Only 'yes' will be accepted to approve. Enter a value: So Terraform looks for the values of your variables as long as they have the prefix TF_VAR_ but there are exceptions.","title":"environmental variables"},{"location":"lesson2/#tfvars","text":"Terraform can also take the values of variables from a tfvars file. Make sure to erase your environmental variables from the previous section. Add a file called guff.tfvars user = \"guff\" And apply. $ terraform apply var.user Enter a value: So that didn't work. There's a convention for variable files \"tfvars\", the old convention is to use a file called terraform.tfvars but you can now use multiple tfvar files as long as they have auto in their name. Rename guff.tfvars guff.auto.tfvars and re-apply.","title":"Tfvars"},{"location":"lesson2/#outputs","text":"It's also good practice to include your outputs. This helps with debugging and making your template or module extendible. By convention it's called Outputs.tf output \"hello_world\" { description = \"The Output of the Null resource\" value = null_resource . hello_world } Now when you apply, you should see something like this at the end of your output; Apply complete! Resources: 1 added, 0 changed, 0 destroyed. Outputs: hello_world = { \"id\" = \"562214568453658147\" } Takeaways variables overrides syntax checking outputs defaults cli usage environmental variables tfvars state with null resource local execs are contents not infrastructure so there's no record in state","title":"Outputs"},{"location":"lesson2/#exercises","text":"What other data types can a variable be? Modify the example to use a list type. What other file formats are supported?","title":"Exercises"},{"location":"lesson2/#questions","text":"","title":"Questions"},{"location":"lesson2/#documentation","text":"https://www.terraform.io/docs/configuration/syntax-json.html For more on variables see the Hashicorp docs: https://www.terraform.io/docs/configuration/variables.html","title":"Documentation"},{"location":"lesson3/","text":"Lesson 103 Templates Convert to using a template Copy lesson 2 Terraform code, to lesson3 and delete terraform.tfstate . Create a folder in lesson3 called template and add hello.tmpl : hello from ${ ip } for ${ user } This is not much different than a jinja2 template, and achieves the same ends. Adding and using a Module Add module.ip.tf module \"ip\" { source = \"JamesWoolfenden/ip/http\" version = \"0.2.8\" } A module is a re-usable component of Terraform. The source element \"JamesWoolfenden/ip/http\" is a reference to the Terraform Registry https://registry.terraform.io/ The details for a module can be seen there https://registry.terraform.io/modules/JamesWoolfenden/ip/http/0.2.8 . The version element allows us to fix the dependency. The module requires the http provider, so that needs to added. Add module reference provider.http.tf . provider \"http\" { version = \"1.1\" } Finally modify null_resource.helloworld.tf resource \"null_resource\" \"hello_world\" { provisioner \"local-exec\" { # This is a comment command = \"echo '${templatefile(\"${path.module}/template/hello.tmpl\", { ip = module.ip.ip, user = var . user } ) } '\" } } This now uses the templatefile function with supplied values for IP and user. Time to try it: $ terraform apply module.ip.data.http.ip: Refreshing state... An execution plan has been generated and is shown below. Resource actions are indicated with the following symbols: + create Terraform will perform the following actions: # null_resource.hello_world will be created + resource \"null_resource\" \"hello_world\" { + id = ( known after apply ) } Plan: 1 to add, 0 to change, 0 to destroy. Do you want to perform these actions? Terraform will perform the actions described above. Only 'yes' will be accepted to approve. Enter a value: yes null_resource.hello_world: Creating... null_resource.hello_world: Provisioning with 'local-exec' ... null_resource.hello_world ( local-exec ) : Executing: [ \"cmd\" \"/C\" \"echo 'hello from 86.157.143.189 for guff'\" ] null_resource.hello_world ( local-exec ) : 'hello from 86.157.143.189 for guff' null_resource.hello_world: Creation complete after 0s [ id = 3464807873684983853 ] Apply complete! Resources: 1 added, 0 changed, 0 destroyed. Outputs: hello_world = { \"id\" = \"3464807873684983853\" } So that's using modules, templates and Terraform functions. Major features but simple examples. terraform fmt Terraform fmt rewrites \"Terraform configuration files to a canonical format and style\", that means no more arguments about spaces for layout. There is only the true path of fmt. Run it on your template. $ terraform fmt null_resource.helloworld.tf Using the lessons from earlier refactor this chapter. Takeaways modules templating fmt functions registry Questions Documentation https://registry.terraform.io/modules/JamesWoolfenden/ip/http/0.2.8 https://www.terraform.io/docs/configuration/functions/templatefile.html https://www.terraform.io/docs/configuration/modules.html","title":"Lesson 103"},{"location":"lesson3/#lesson-103-templates","text":"","title":"Lesson 103 Templates"},{"location":"lesson3/#convert-to-using-a-template","text":"Copy lesson 2 Terraform code, to lesson3 and delete terraform.tfstate . Create a folder in lesson3 called template and add hello.tmpl : hello from ${ ip } for ${ user } This is not much different than a jinja2 template, and achieves the same ends.","title":"Convert to using a template"},{"location":"lesson3/#adding-and-using-a-module","text":"Add module.ip.tf module \"ip\" { source = \"JamesWoolfenden/ip/http\" version = \"0.2.8\" } A module is a re-usable component of Terraform. The source element \"JamesWoolfenden/ip/http\" is a reference to the Terraform Registry https://registry.terraform.io/ The details for a module can be seen there https://registry.terraform.io/modules/JamesWoolfenden/ip/http/0.2.8 . The version element allows us to fix the dependency. The module requires the http provider, so that needs to added. Add module reference provider.http.tf . provider \"http\" { version = \"1.1\" } Finally modify null_resource.helloworld.tf resource \"null_resource\" \"hello_world\" { provisioner \"local-exec\" { # This is a comment command = \"echo '${templatefile(\"${path.module}/template/hello.tmpl\", { ip = module.ip.ip, user = var . user } ) } '\" } } This now uses the templatefile function with supplied values for IP and user. Time to try it: $ terraform apply module.ip.data.http.ip: Refreshing state... An execution plan has been generated and is shown below. Resource actions are indicated with the following symbols: + create Terraform will perform the following actions: # null_resource.hello_world will be created + resource \"null_resource\" \"hello_world\" { + id = ( known after apply ) } Plan: 1 to add, 0 to change, 0 to destroy. Do you want to perform these actions? Terraform will perform the actions described above. Only 'yes' will be accepted to approve. Enter a value: yes null_resource.hello_world: Creating... null_resource.hello_world: Provisioning with 'local-exec' ... null_resource.hello_world ( local-exec ) : Executing: [ \"cmd\" \"/C\" \"echo 'hello from 86.157.143.189 for guff'\" ] null_resource.hello_world ( local-exec ) : 'hello from 86.157.143.189 for guff' null_resource.hello_world: Creation complete after 0s [ id = 3464807873684983853 ] Apply complete! Resources: 1 added, 0 changed, 0 destroyed. Outputs: hello_world = { \"id\" = \"3464807873684983853\" } So that's using modules, templates and Terraform functions. Major features but simple examples.","title":"Adding and using a Module"},{"location":"lesson3/#terraform-fmt","text":"Terraform fmt rewrites \"Terraform configuration files to a canonical format and style\", that means no more arguments about spaces for layout. There is only the true path of fmt. Run it on your template. $ terraform fmt null_resource.helloworld.tf Using the lessons from earlier refactor this chapter. Takeaways modules templating fmt functions registry","title":"terraform fmt"},{"location":"lesson3/#questions","text":"","title":"Questions"},{"location":"lesson3/#documentation","text":"https://registry.terraform.io/modules/JamesWoolfenden/ip/http/0.2.8 https://www.terraform.io/docs/configuration/functions/templatefile.html https://www.terraform.io/docs/configuration/modules.html","title":"Documentation"},{"location":"lesson4/","text":"Lesson 104 Making an AWS Lambda AWS Authentication Test you have AWS authentication set-up, I tend to use a simple S3 command: $ aws s3 ls 2020 -02-14 17 :44:39 trails-680235478471 2019 -10-12 12 :01:30 whosebucketisitanyway This is usually enough to tell me AWS is authenticated, unless you've not made any buckets. Add Python code Make a folder called code. Add lambda.py to it. import json def lambda_handler ( event , context ): return { 'statusCode' : 200 , 'body' : json . dumps ( 'Hello from Lambda!' ) } Terraform Archive Create a zip of the Python code, use archive provider data.archive_file.helloworld.tf data \"archive_file\" \"hello-world\" { type = \"zip\" source_file = \"${path.module}/code/lambda.py\" output_path = \"${path.module}/lambda.zip\" } Add Providers This Supplies the Auth, Resources and the Providers needed for zip AWS Add providers.tf provider \"aws\" { version = \"~>2.50\" region = \"us-west-2\" } provider \"archive\" { version = \"1.3\" } There's nothing obvious connecting the AWS auth, but the AWS keychain that we validated earlier will be automatically picked up by the AWS provider. Add the Lambda resource Create aws_lambda_function.hello_world.tf resource \"aws_lambda_function\" \"hello_world\" { filename = \"${path.module}/lambda.zip\" function_name = \"hello-world\" handler = \"lambda.lambda_handler\" role = data . aws_iam_role . basic . arn runtime = \"python3.7\" source_code_hash = data . archive_file . hello-world . output_base64sha256 } This brings the whole template together, most of this is pretty obvious, source_code_hash serves two purposes, the hash will change if the zipped python changes, and it creates a link between the archive and the lambda resources to ensure that the zip happens first. Role Finally the Lambda needs a role for authentication for itself, there is a pre-existing basic role for executing lambda \"lambda_basic_execution\". Create data aws_iam_role.basic.tf with: data \"aws_iam_role\" \"basic\" { name = \"lambda_basic_execution\" } This role has only an inline IAM policy to access Cloud watch logs. { \"Version\" : \"2012-10-17\" , \"Statement\" : [ { \"Effect\" : \"Allow\" , \"Action\" : [ \"logs:CreateLogGroup\" , \"logs:CreateLogStream\" , \"logs:PutLogEvents\" ], \"Resource\" : \"arn:aws:logs:*:*:*\" } ] } Time to build and apply the Lambda. $ terraform apply data.archive_file.hello-world: Refreshing state... data.aws_iam_role.basic: Refreshing state... An execution plan has been generated and is shown below. Resource actions are indicated with the following symbols: + create Terraform will perform the following actions: # aws_lambda_function.hello_world will be created + resource \"aws_lambda_function\" \"hello_world\" { + arn = ( known after apply ) + filename = \"./lambda.zip\" + function_name = \"hello-world\" + handler = \"lambda.lambda_handler\" + id = ( known after apply ) + invoke_arn = ( known after apply ) + last_modified = ( known after apply ) + memory_size = 128 + publish = false + qualified_arn = ( known after apply ) + reserved_concurrent_executions = -1 + role = \"arn:aws:iam::680235478471:role/lambda_basic_execution\" + runtime = \"python3.7\" + source_code_hash = \"rna/NuWSsy6/EZaDG7bGpz1rfX1bawF3OAKjyjBc/i8=\" + source_code_size = ( known after apply ) + timeout = 3 + version = ( known after apply ) + tracing_config { + mode = ( known after apply ) } } Plan: 1 to add, 0 to change, 0 to destroy. Do you want to perform these actions? Terraform will perform the actions described above. Only 'yes' will be accepted to approve. Enter a value: yes aws_lambda_function.hello_world: Creating... aws_lambda_function.hello_world: Creation complete after 9s [ id = hello-world ] Testing You can verify that the Lambda works by invoking it at the command line. $ aws lambda invoke --function-name hello-world hello.json { \"StatusCode\" : 200 , \"ExecutedVersion\" : \" $LATEST \" } State Change the name of the lambda in code and terraform apply , what do you expect to happen? Change the name of the lambda in the AWS console, and terraform apply , what do you expect to happen? Refactor Using the lessons from earlier refactor this chapter. Takeaways Auth Archive Lambda Data resource Cli Questions How do you specify an AWS profile? Why might that be a bad idea? Documentation https://www.terraform.io/docs/providers/aws/index.html","title":"Lesson 104"},{"location":"lesson4/#lesson-104-making-an-aws-lambda","text":"","title":"Lesson 104 Making an AWS Lambda"},{"location":"lesson4/#aws-authentication","text":"Test you have AWS authentication set-up, I tend to use a simple S3 command: $ aws s3 ls 2020 -02-14 17 :44:39 trails-680235478471 2019 -10-12 12 :01:30 whosebucketisitanyway This is usually enough to tell me AWS is authenticated, unless you've not made any buckets.","title":"AWS Authentication"},{"location":"lesson4/#add-python-code","text":"Make a folder called code. Add lambda.py to it. import json def lambda_handler ( event , context ): return { 'statusCode' : 200 , 'body' : json . dumps ( 'Hello from Lambda!' ) }","title":"Add Python code"},{"location":"lesson4/#terraform-archive","text":"Create a zip of the Python code, use archive provider data.archive_file.helloworld.tf data \"archive_file\" \"hello-world\" { type = \"zip\" source_file = \"${path.module}/code/lambda.py\" output_path = \"${path.module}/lambda.zip\" }","title":"Terraform Archive"},{"location":"lesson4/#add-providers","text":"This Supplies the Auth, Resources and the Providers needed for zip AWS Add providers.tf provider \"aws\" { version = \"~>2.50\" region = \"us-west-2\" } provider \"archive\" { version = \"1.3\" } There's nothing obvious connecting the AWS auth, but the AWS keychain that we validated earlier will be automatically picked up by the AWS provider.","title":"Add Providers"},{"location":"lesson4/#add-the-lambda-resource","text":"Create aws_lambda_function.hello_world.tf resource \"aws_lambda_function\" \"hello_world\" { filename = \"${path.module}/lambda.zip\" function_name = \"hello-world\" handler = \"lambda.lambda_handler\" role = data . aws_iam_role . basic . arn runtime = \"python3.7\" source_code_hash = data . archive_file . hello-world . output_base64sha256 } This brings the whole template together, most of this is pretty obvious, source_code_hash serves two purposes, the hash will change if the zipped python changes, and it creates a link between the archive and the lambda resources to ensure that the zip happens first.","title":"Add the Lambda resource"},{"location":"lesson4/#role","text":"Finally the Lambda needs a role for authentication for itself, there is a pre-existing basic role for executing lambda \"lambda_basic_execution\". Create data aws_iam_role.basic.tf with: data \"aws_iam_role\" \"basic\" { name = \"lambda_basic_execution\" } This role has only an inline IAM policy to access Cloud watch logs. { \"Version\" : \"2012-10-17\" , \"Statement\" : [ { \"Effect\" : \"Allow\" , \"Action\" : [ \"logs:CreateLogGroup\" , \"logs:CreateLogStream\" , \"logs:PutLogEvents\" ], \"Resource\" : \"arn:aws:logs:*:*:*\" } ] } Time to build and apply the Lambda. $ terraform apply data.archive_file.hello-world: Refreshing state... data.aws_iam_role.basic: Refreshing state... An execution plan has been generated and is shown below. Resource actions are indicated with the following symbols: + create Terraform will perform the following actions: # aws_lambda_function.hello_world will be created + resource \"aws_lambda_function\" \"hello_world\" { + arn = ( known after apply ) + filename = \"./lambda.zip\" + function_name = \"hello-world\" + handler = \"lambda.lambda_handler\" + id = ( known after apply ) + invoke_arn = ( known after apply ) + last_modified = ( known after apply ) + memory_size = 128 + publish = false + qualified_arn = ( known after apply ) + reserved_concurrent_executions = -1 + role = \"arn:aws:iam::680235478471:role/lambda_basic_execution\" + runtime = \"python3.7\" + source_code_hash = \"rna/NuWSsy6/EZaDG7bGpz1rfX1bawF3OAKjyjBc/i8=\" + source_code_size = ( known after apply ) + timeout = 3 + version = ( known after apply ) + tracing_config { + mode = ( known after apply ) } } Plan: 1 to add, 0 to change, 0 to destroy. Do you want to perform these actions? Terraform will perform the actions described above. Only 'yes' will be accepted to approve. Enter a value: yes aws_lambda_function.hello_world: Creating... aws_lambda_function.hello_world: Creation complete after 9s [ id = hello-world ]","title":"Role"},{"location":"lesson4/#testing","text":"You can verify that the Lambda works by invoking it at the command line. $ aws lambda invoke --function-name hello-world hello.json { \"StatusCode\" : 200 , \"ExecutedVersion\" : \" $LATEST \" }","title":"Testing"},{"location":"lesson4/#state","text":"Change the name of the lambda in code and terraform apply , what do you expect to happen? Change the name of the lambda in the AWS console, and terraform apply , what do you expect to happen?","title":"State"},{"location":"lesson4/#refactor","text":"Using the lessons from earlier refactor this chapter. Takeaways Auth Archive Lambda Data resource Cli","title":"Refactor"},{"location":"lesson4/#questions","text":"How do you specify an AWS profile? Why might that be a bad idea?","title":"Questions"},{"location":"lesson4/#documentation","text":"https://www.terraform.io/docs/providers/aws/index.html","title":"Documentation"},{"location":"lesson5/","text":"Lesson 105 Preferred Tools and set-up The difference between a success and failure can be down to the tooling. These options are proven. VCS The preference is always to use SAS VCS rather than on premise or self hosted solutions, as this gives you the best access to integrating with other tools. Github . Has better integration with Terraform, the Registry and Cloud, and other CI tools and the public clouds. Gitlab . Does more than just look after your code. CI/CD Having versioned modules is essential, Infra code should be treated exactly as application code. Github Actions This provides basic functionality for builds without having to leave the platform. I use this for all new module pipelines. Free. The example below checks and validates and module and then versions it. --- name : Verify and Bump on : push : branches : - master jobs : examples : name : \"Terraform (examples)\" runs-on : ubuntu-latest steps : - name : \"Checkout\" uses : actions/checkout@master - name : \"Terraform Init\" uses : hashicorp/terraform-github-actions@master with : tf_actions_version : 0.12.20 tf_actions_subcommand : \"init\" tf_actions_working_dir : \"example/examplea\" - name : \"Terraform Validate\" uses : hashicorp/terraform-github-actions@master with : tf_actions_version : 0.12.20 tf_actions_subcommand : \"validate\" tf_actions_working_dir : \"example/examplea\" build : name : versioning runs-on : ubuntu-latest steps : - uses : actions/checkout@master - name : Bump version and push tag uses : anothrNick/github-tag-action@master env : GITHUB_TOKEN : ${{ secrets.GITHUB_TOKEN }} DEFAULT_BUMP : patch WITH_V : \"true\" needs : examples Terraform Cloud Terraform Enterprise now with a free tier, a good base if all your builds are only infrastructure. CircleCI The stand out best current option for CI. Given a choice, this is it. Below, is a basic node CI process. Name it version : 2.1 orbs : aws-cli : circleci/aws-cli@0.1.13 jobs : build : working_directory : ~/build docker : - image : circleci/node steps : - checkout - restore_cache : key : dependency-cache-{{ checksum \"package.json\" }} - run : name : install-npm command : npm install - run : name : pack command : npm pack - run : name : copy command : | mkdir ~/output/ cp *.tgz ~/output/ - save_cache : key : dependency-cache-{{ checksum \"package.json\" }} paths : - ./node_modules - store_artifacts : path : ~/output deploy : working_directory : ~/build docker : - image : circleci/node steps : - checkout - aws-cli/install - aws-cli/configure - run : name : Deploy command : npm run deploy workflows : version : 2 build-and-deploy : jobs : - build - deploy : requires : - build filters : branches : only : master context : AWS Travis . The old best SAS option and still good enough. Used for all old module pipelines. Free for Public repos. The example below also does a basic tests set-up and versioning for a given module. --- # yamllint disable rule:line-length dist : trusty sudo : required services : - docker branches : only : - master env : - VERSION=\"0.1.$TRAVIS_BUILD_NUMBER\" addons : apt : packages : - git - curl before_script : - export TERRAFORM_VERSION=$(curl -s https://checkpoint-api.hashicorp.com/v1/check/terraform | jq -r -M '.current_version') - curl --silent --output terraform.zip \"https://releases.hashicorp.com/terraform/${TERRAFORM_VERSION}/terraform_${TERRAFORM_VERSION}_linux_amd64.zip\" - unzip terraform.zip ; rm -f terraform.zip; chmod +x terraform - mkdir -p ${HOME}/bin ; export PATH=${PATH}:${HOME}/bin; mv terraform ${HOME}/bin/ - terraform -v script : - terraform init -get-plugins -backend=false -input=false - terraform init -get -backend=false -input=false - terraform fmt - bash validate.sh after_success : - git config --global user.email \"builds@travis-ci.com\" - git config --global user.name \"Travis CI\" - export GIT_TAG=$VERSION - git tag $GIT_TAG -a -m \"Generated tag from TravisCI build $VERSION\" - git push --quiet https://$TAGAUTH@github.com/jameswoolfenden/terraform-aws-snstoslack $GIT_TAG > /dev/null 2>&1 TeamCity . If you're not using a SAS product this is best option. https://github.com/JamesWoolfenden/terraform-aws-teamcity I'm sure there are other good SAS CI tools available e.g. Codefresh, I could easily do a list of tools to avoid. IDE I haven't used anything except VSCode for sometime. VSCode Extension https://marketplace.visualstudio.com/items?itemName=mauve.terraform Atom . I used to use this. Intellij Also supports an HCL plugin. Terraform Tools I'm always on the lookout for new and improved tools, so surprisingly this a short list, but these ones have proven to be essential. Terraformer https://github.com/GoogleCloudPlatform/terraformer . This reverse engineers infrastructure into Terraform, supports just about anything. Checkov https://checkov.io . The stand-out best analysis tool for Terraform. Tests against the CIS Standards. The Pre-commit framework https://pre-commit.com/ . Manages your code, does many useful things like not letting add secrets to your code. My current set up for pre-commit is supplied .pre-commit-config.yaml this is suitable for Terraform only repositories. Aws-vault https://github.com/99designs/aws-vault \"A vault for securely storing and accessing AWS credentials in development environments\" Terraform-docs https://github.com/segmentio/terraform-docs To generate docs from your TF code. Saml2aws https://github.com/Versent/saml2aws \"CLI tool which enables you to login and retrieve AWS temporary credentials using a SAML IDP\" --- # yamllint disable rule:line-length default_language_version : python : python3 repos : - repo : git://github.com/pre-commit/pre-commit-hooks rev : v2.5.0 hooks : - id : check-json - id : check-merge-conflict - id : trailing-whitespace - id : end-of-file-fixer - id : check-yaml - id : check-added-large-files - id : pretty-format-json args : - --autofix - id : detect-aws-credentials - id : detect-private-key - repo : git://github.com/Lucas-C/pre-commit-hooks rev : v1.1.7 hooks : - id : forbid-tabs exclude_types : [ python , javascript , dtd , markdown , makefile , xml ] exclude : binary|\\.bin$ - repo : git://github.com/jameswoolfenden/pre-commit-shell rev : 0.0.2 hooks : - id : shell-lint - repo : git://github.com/igorshubovych/markdownlint-cli rev : v0.22.0 hooks : - id : markdownlint - repo : git://github.com/adrienverge/yamllint rev : v1.20.0 hooks : - id : yamllint name : yamllint description : This hook runs yamllint. entry : yamllint language : python types : [ file , yaml ] - repo : git://github.com/jameswoolfenden/pre-commit rev : 0.1.17 hooks : - id : terraform-fmt - id : checkov-scan language_version : python3.7 - id : tf2docs language_version : python3.7 Testing You may notice the lack of unit testing tooling, this is not an omission. Exercises Create an Account on Terraform cloud - https://app.terraform.io Look at the published modules modules on the Registry https://registry.terraform.io Takeaways tools no unit practical unit testing Questions Why are the options for unit testing, what's wrong? Documentation There is publicly maintained list of Terraform tools https://github.com/shuaibiyy/awesome-terraform","title":"Lesson 105"},{"location":"lesson5/#lesson-105","text":"","title":"Lesson 105"},{"location":"lesson5/#preferred-tools-and-set-up","text":"The difference between a success and failure can be down to the tooling. These options are proven.","title":"Preferred Tools and set-up"},{"location":"lesson5/#vcs","text":"The preference is always to use SAS VCS rather than on premise or self hosted solutions, as this gives you the best access to integrating with other tools. Github . Has better integration with Terraform, the Registry and Cloud, and other CI tools and the public clouds. Gitlab . Does more than just look after your code.","title":"VCS"},{"location":"lesson5/#cicd","text":"Having versioned modules is essential, Infra code should be treated exactly as application code. Github Actions This provides basic functionality for builds without having to leave the platform. I use this for all new module pipelines. Free. The example below checks and validates and module and then versions it. --- name : Verify and Bump on : push : branches : - master jobs : examples : name : \"Terraform (examples)\" runs-on : ubuntu-latest steps : - name : \"Checkout\" uses : actions/checkout@master - name : \"Terraform Init\" uses : hashicorp/terraform-github-actions@master with : tf_actions_version : 0.12.20 tf_actions_subcommand : \"init\" tf_actions_working_dir : \"example/examplea\" - name : \"Terraform Validate\" uses : hashicorp/terraform-github-actions@master with : tf_actions_version : 0.12.20 tf_actions_subcommand : \"validate\" tf_actions_working_dir : \"example/examplea\" build : name : versioning runs-on : ubuntu-latest steps : - uses : actions/checkout@master - name : Bump version and push tag uses : anothrNick/github-tag-action@master env : GITHUB_TOKEN : ${{ secrets.GITHUB_TOKEN }} DEFAULT_BUMP : patch WITH_V : \"true\" needs : examples Terraform Cloud Terraform Enterprise now with a free tier, a good base if all your builds are only infrastructure. CircleCI The stand out best current option for CI. Given a choice, this is it. Below, is a basic node CI process. Name it version : 2.1 orbs : aws-cli : circleci/aws-cli@0.1.13 jobs : build : working_directory : ~/build docker : - image : circleci/node steps : - checkout - restore_cache : key : dependency-cache-{{ checksum \"package.json\" }} - run : name : install-npm command : npm install - run : name : pack command : npm pack - run : name : copy command : | mkdir ~/output/ cp *.tgz ~/output/ - save_cache : key : dependency-cache-{{ checksum \"package.json\" }} paths : - ./node_modules - store_artifacts : path : ~/output deploy : working_directory : ~/build docker : - image : circleci/node steps : - checkout - aws-cli/install - aws-cli/configure - run : name : Deploy command : npm run deploy workflows : version : 2 build-and-deploy : jobs : - build - deploy : requires : - build filters : branches : only : master context : AWS Travis . The old best SAS option and still good enough. Used for all old module pipelines. Free for Public repos. The example below also does a basic tests set-up and versioning for a given module. --- # yamllint disable rule:line-length dist : trusty sudo : required services : - docker branches : only : - master env : - VERSION=\"0.1.$TRAVIS_BUILD_NUMBER\" addons : apt : packages : - git - curl before_script : - export TERRAFORM_VERSION=$(curl -s https://checkpoint-api.hashicorp.com/v1/check/terraform | jq -r -M '.current_version') - curl --silent --output terraform.zip \"https://releases.hashicorp.com/terraform/${TERRAFORM_VERSION}/terraform_${TERRAFORM_VERSION}_linux_amd64.zip\" - unzip terraform.zip ; rm -f terraform.zip; chmod +x terraform - mkdir -p ${HOME}/bin ; export PATH=${PATH}:${HOME}/bin; mv terraform ${HOME}/bin/ - terraform -v script : - terraform init -get-plugins -backend=false -input=false - terraform init -get -backend=false -input=false - terraform fmt - bash validate.sh after_success : - git config --global user.email \"builds@travis-ci.com\" - git config --global user.name \"Travis CI\" - export GIT_TAG=$VERSION - git tag $GIT_TAG -a -m \"Generated tag from TravisCI build $VERSION\" - git push --quiet https://$TAGAUTH@github.com/jameswoolfenden/terraform-aws-snstoslack $GIT_TAG > /dev/null 2>&1 TeamCity . If you're not using a SAS product this is best option. https://github.com/JamesWoolfenden/terraform-aws-teamcity I'm sure there are other good SAS CI tools available e.g. Codefresh, I could easily do a list of tools to avoid.","title":"CI/CD"},{"location":"lesson5/#ide","text":"I haven't used anything except VSCode for sometime. VSCode Extension https://marketplace.visualstudio.com/items?itemName=mauve.terraform Atom . I used to use this. Intellij Also supports an HCL plugin.","title":"IDE"},{"location":"lesson5/#terraform-tools","text":"I'm always on the lookout for new and improved tools, so surprisingly this a short list, but these ones have proven to be essential. Terraformer https://github.com/GoogleCloudPlatform/terraformer . This reverse engineers infrastructure into Terraform, supports just about anything. Checkov https://checkov.io . The stand-out best analysis tool for Terraform. Tests against the CIS Standards. The Pre-commit framework https://pre-commit.com/ . Manages your code, does many useful things like not letting add secrets to your code. My current set up for pre-commit is supplied .pre-commit-config.yaml this is suitable for Terraform only repositories. Aws-vault https://github.com/99designs/aws-vault \"A vault for securely storing and accessing AWS credentials in development environments\" Terraform-docs https://github.com/segmentio/terraform-docs To generate docs from your TF code. Saml2aws https://github.com/Versent/saml2aws \"CLI tool which enables you to login and retrieve AWS temporary credentials using a SAML IDP\" --- # yamllint disable rule:line-length default_language_version : python : python3 repos : - repo : git://github.com/pre-commit/pre-commit-hooks rev : v2.5.0 hooks : - id : check-json - id : check-merge-conflict - id : trailing-whitespace - id : end-of-file-fixer - id : check-yaml - id : check-added-large-files - id : pretty-format-json args : - --autofix - id : detect-aws-credentials - id : detect-private-key - repo : git://github.com/Lucas-C/pre-commit-hooks rev : v1.1.7 hooks : - id : forbid-tabs exclude_types : [ python , javascript , dtd , markdown , makefile , xml ] exclude : binary|\\.bin$ - repo : git://github.com/jameswoolfenden/pre-commit-shell rev : 0.0.2 hooks : - id : shell-lint - repo : git://github.com/igorshubovych/markdownlint-cli rev : v0.22.0 hooks : - id : markdownlint - repo : git://github.com/adrienverge/yamllint rev : v1.20.0 hooks : - id : yamllint name : yamllint description : This hook runs yamllint. entry : yamllint language : python types : [ file , yaml ] - repo : git://github.com/jameswoolfenden/pre-commit rev : 0.1.17 hooks : - id : terraform-fmt - id : checkov-scan language_version : python3.7 - id : tf2docs language_version : python3.7","title":"Terraform Tools"},{"location":"lesson5/#testing","text":"You may notice the lack of unit testing tooling, this is not an omission.","title":"Testing"},{"location":"lesson5/#exercises","text":"Create an Account on Terraform cloud - https://app.terraform.io Look at the published modules modules on the Registry https://registry.terraform.io Takeaways tools no unit practical unit testing","title":"Exercises"},{"location":"lesson5/#questions","text":"Why are the options for unit testing, what's wrong?","title":"Questions"},{"location":"lesson5/#documentation","text":"There is publicly maintained list of Terraform tools https://github.com/shuaibiyy/awesome-terraform","title":"Documentation"},{"location":"lesson6/","text":"Lesson 106 Structure In the last Chapter we covered tools, this chapter focussed on structure. Terraform is a declarative data driven language. As a rule design for replication and clarity and not for logic constructs. Design for a lower cognitive load. How should I layout Terraform project When I first started writing Terraform I wrote a lot of wrapper scripts now I aim to write none. no wrapper scripts Exception- Well I sometime create a makefile or equivalent. Call Terraform on a given path. You may have to repeat yourself but it makes up for it in for clarity and portability. For application related infrastructure, keep the tf with the code it relates to. Account level/environments code is best kept separate, this would be VPC, routing, security. With Cloud native services, The separation between Infrastructure from application is getting less defined (see lesson 201). Preference is for Clarity, repeat for clarity. Files Naming lowercase with _ separators. Standard files variables.tf,outputs.tf, locals.tf I follow a 1 resource per file with files named after resources, although dumping in main.tf is common easier to navigate easier to compare easier to debug Testing As alluded previously to, I have yet to fins a satisfactory tool/solution for unit testing Checkov. Terraform init, plan, fmt, validate. Only test whats you can reasonably be expected to fix. Some use AWS-spec. I do not. Modules I have a standard process and skeleton for starting, building, documenting and versioning modules. This is the MVP of module creation: Make a copy of the Lambda code from lesson 4. Create a folder called example, and move the provider to it. Then add module.lambda.tf module \"lambda\" { source=\"../\" } in aws_lambda_function.hello_world.tf resource \"aws_lambda_function\" \"hello_world\" { filename = \"${path.module}/lambda.zip\" function_name = var.name handler = \"lambda.lambda_handler\" role = data.aws_iam_role.basic.arn runtime = \"python3.7\" source_code_hash = data.archive_file.hello-world.output_base64sha256 } And add variables.tf variable \"name\" { description=\"The name of the lambda\" type=string } Your module now requires the value for var.name , add that to your module reference in example, put your own value for the name: module \"lambda\" { source= \"../\" name = \"James made me do it\" } Open the example folder in your console, and Terraform init and apply. That's the basics. Create build process for modules. Build to TF module guidelines. Build for the Registry. Don't put all your modules in a monolith repo, amongst other things this makes versioning hard. private repos, are forgotten not reused, never get seen or tested. Refactor Using the lessons from earlier refactor this chapter. Exercises Add a reference to a version of a module. Takeaways modules are like micro-services, keep them separate. Questions Documentation https://www.terraform.io/docs/modules/index.html","title":"Lesson 106"},{"location":"lesson6/#lesson-106-structure","text":"In the last Chapter we covered tools, this chapter focussed on structure. Terraform is a declarative data driven language. As a rule design for replication and clarity and not for logic constructs. Design for a lower cognitive load.","title":"Lesson 106 Structure"},{"location":"lesson6/#how-should-i-layout-terraform-project","text":"When I first started writing Terraform I wrote a lot of wrapper scripts now I aim to write none. no wrapper scripts Exception- Well I sometime create a makefile or equivalent. Call Terraform on a given path. You may have to repeat yourself but it makes up for it in for clarity and portability. For application related infrastructure, keep the tf with the code it relates to. Account level/environments code is best kept separate, this would be VPC, routing, security. With Cloud native services, The separation between Infrastructure from application is getting less defined (see lesson 201). Preference is for Clarity, repeat for clarity.","title":"How should I layout Terraform project"},{"location":"lesson6/#files","text":"Naming lowercase with _ separators. Standard files variables.tf,outputs.tf, locals.tf I follow a 1 resource per file with files named after resources, although dumping in main.tf is common easier to navigate easier to compare easier to debug","title":"Files"},{"location":"lesson6/#testing","text":"As alluded previously to, I have yet to fins a satisfactory tool/solution for unit testing Checkov. Terraform init, plan, fmt, validate. Only test whats you can reasonably be expected to fix. Some use AWS-spec. I do not.","title":"Testing"},{"location":"lesson6/#modules","text":"I have a standard process and skeleton for starting, building, documenting and versioning modules. This is the MVP of module creation: Make a copy of the Lambda code from lesson 4. Create a folder called example, and move the provider to it. Then add module.lambda.tf module \"lambda\" { source=\"../\" } in aws_lambda_function.hello_world.tf resource \"aws_lambda_function\" \"hello_world\" { filename = \"${path.module}/lambda.zip\" function_name = var.name handler = \"lambda.lambda_handler\" role = data.aws_iam_role.basic.arn runtime = \"python3.7\" source_code_hash = data.archive_file.hello-world.output_base64sha256 } And add variables.tf variable \"name\" { description=\"The name of the lambda\" type=string } Your module now requires the value for var.name , add that to your module reference in example, put your own value for the name: module \"lambda\" { source= \"../\" name = \"James made me do it\" } Open the example folder in your console, and Terraform init and apply. That's the basics. Create build process for modules. Build to TF module guidelines. Build for the Registry. Don't put all your modules in a monolith repo, amongst other things this makes versioning hard. private repos, are forgotten not reused, never get seen or tested.","title":"Modules"},{"location":"lesson6/#refactor","text":"Using the lessons from earlier refactor this chapter.","title":"Refactor"},{"location":"lesson6/#exercises","text":"Add a reference to a version of a module. Takeaways modules are like micro-services, keep them separate.","title":"Exercises"},{"location":"lesson6/#questions","text":"","title":"Questions"},{"location":"lesson6/#documentation","text":"https://www.terraform.io/docs/modules/index.html","title":"Documentation"},{"location":"lesson7/","text":"Lesson 7 State After starting a project getting Access to a Cloud account/project, creating a state bucket is step 2. This is usually an S3 bucket, Cloud storage, Blob Storage or Terraform Cloud Workspace. Having a remotely managed state file allows you to cooperate on using and creating infrastructure code. A statefiles' location is determined when you invoke Terraform init. -- Local State When you first start and apply your template, a state file is left behind. { \"version\" : 4 , \"terraform_version\" : \"0.12.20\" , \"serial\" : 9 , \"lineage\" : \"c430de7f-a3f5-e2d1-f912-0beb92340157\" , \"outputs\" : {}, \"resources\" : [ { \"mode\" : \"data\" , \"type\" : \"archive_file\" , \"name\" : \"hello-world\" , \"provider\" : \"provider.archive\" , \"instances\" : [ { \"schema_version\" : 0 , \"attributes\" : { \"excludes\" : null , \"id\" : \"57f31171437c7fb9dde5382167d421d966eb0707\" , \"output_base64sha256\" : \"rna/NuWSsy6/EZaDG7bGpz1rfX1bawF3OAKjyjBc/i8=\" , \"output_md5\" : \"5ddf9823dd4e8dbf3c0d8c2e642a2a05\" , \"output_path\" : \"./lambda.zip\" , \"output_sha\" : \"57f31171437c7fb9dde5382167d421d966eb0707\" , \"output_size\" : 262 , \"source\" : [], \"source_content\" : null , \"source_content_filename\" : null , \"source_dir\" : null , \"source_file\" : \"./code/lambda.py\" , \"type\" : \"zip\" } } ] }, { \"mode\" : \"data\" , \"type\" : \"aws_iam_role\" , \"name\" : \"basic\" , \"provider\" : \"provider.aws\" , \"instances\" : [ { \"schema_version\" : 0 , \"attributes\" : { \"arn\" : \"arn:aws:iam::680235478471:role/lambda_basic_execution\" , \"assume_role_policy\" : \"{\\\"Version\\\":\\\"2012-10-17\\\",\\\"Statement\\\":[{\\\"Effect\\\":\\\"Allow\\\",\\\"Principal\\\":{\\\"Service\\\":\\\"lambda.amazonaws.com\\\"},\\\"Action\\\":\\\"sts:AssumeRole\\\"}]}\" , \"assume_role_policy_document\" : null , \"create_date\" : \"2016-10-04T13:19:01Z\" , \"description\" : \"\" , \"id\" : \"lambda_basic_execution\" , \"max_session_duration\" : 3600 , \"name\" : \"lambda_basic_execution\" , \"path\" : \"/\" , \"permissions_boundary\" : \"\" , \"role_id\" : null , \"role_name\" : null , \"unique_id\" : \"AROAJLLUCPL4OFV5WAGMM\" } } ] }, { \"mode\" : \"managed\" , \"type\" : \"aws_lambda_function\" , \"name\" : \"hello_world\" , \"provider\" : \"provider.aws\" , \"instances\" : [ { \"schema_version\" : 0 , \"attributes\" : { \"arn\" : \"arn:aws:lambda:us-west-2:680235478471:function:hello-world\" , \"dead_letter_config\" : [], \"description\" : \"\" , \"environment\" : [], \"filename\" : \"./lambda.zip\" , \"function_name\" : \"hello-world\" , \"handler\" : \"lambda.lambda_handler\" , \"id\" : \"hello-world\" , \"invoke_arn\" : \"arn:aws:apigateway:us-west-2:lambda:path/2015-03-31/functions/arn:aws:lambda:us-west-2:680235478471:function:hello-world/invocations\" , \"kms_key_arn\" : \"\" , \"last_modified\" : \"2020-02-22T18:15:37.396+0000\" , \"layers\" : null , \"memory_size\" : 128 , \"publish\" : false , \"qualified_arn\" : \"arn:aws:lambda:us-west-2:680235478471:function:hello-world:$LATEST\" , \"reserved_concurrent_executions\" : -1 , \"role\" : \"arn:aws:iam::680235478471:role/lambda_basic_execution\" , \"runtime\" : \"python3.7\" , \"s3_bucket\" : null , \"s3_key\" : null , \"s3_object_version\" : null , \"source_code_hash\" : \"rna/NuWSsy6/EZaDG7bGpz1rfX1bawF3OAKjyjBc/i8=\" , \"source_code_size\" : 262 , \"tags\" : null , \"timeout\" : 3 , \"timeouts\" : null , \"tracing_config\" : [ { \"mode\" : \"PassThrough\" } ], \"version\" : \"$LATEST\" , \"vpc_config\" : [] }, \"private\" : \"eyJlMmJmYjczMC1lY2FhLTExZTYtOGY4OC0zNDM2M2JjN2M0YzAiOnsiY3JlYXRlIjo2MDAwMDAwMDAwMDB9fQ==\" } ] } ] } It holds a record of what happened. If you plan to persist what you make, or have more than 1 user, remote state is a must. Do not check in Terraform.tfstate , EVER, as it can contain secrets. Remote state So just about every project should use remote state to secure it's work. To use remote state, a remote state bucket reference is required. To use an S3 bucket, you have a similar section as below in your terraform.tf : terraform { backend \"s3\" { bucket = \"allthestates\" key = \"phrasing/terraform.tfstate\" region = \"eu-west-1\" } } For state buckets the following are critically important: Locking. Considering a locking DynamoDB table early. It's a private bucket. Encryption. It can contain secrets Do not edit manually. Plan to run your Terraform regularly as part of a configuration management process. A State Bucket per AWS account/GCP project/Azure Subscription. S3 versioning. A Statefile per template. And make sure you have unique statefiles. If you use the same statefile in 2 templates what will happen? Try 2 different statefiles from the same template. Reading remote state A one point there was pretty much only one way of finding out what happened in another template, the remote state datasource in Terraform: data \"terraform_remote_state\" \"network\" { backend = \"s3\" config = { bucket = \"allthestates\" key = \"phrasing/terraform.tfstate\" region = \"eu-west-1\" } } This allows you to read the output, if any, of the state file of another template, if permitted. That Datasource used to be the only way of the finding out results of other runs. There are now almost as many Datasource objects as resources, so you don't have to know it's location, which makes for looser coupling. This also allows you to conditionally create or read objects in Terraform. You might still need this, but it's probably a code smell. Importing Most resources support Terraform import statement this allows you to import existing resource into Terraform as if you'd created them. Refactor Using the lessons from earlier refactor this chapter. Takeaways Always use remote state Locking never checkin, update your, .gitignore with an exclusion. Exercises Create a statebucket with Terraform. Migrate to remote state for the lambda template with created in step 4. Create an example to use conditional creation of resources. What could go wrong? How do you manage locking on an S3 bucket? A colleague created S3 bucket via the console, but it should have been done via Terraform, it can't be deleted, how do I turn this into a managed resource? Questions Why might using conditional creation using datasources be a bad idea? What will happen if you share statefiles across templates? What is drift? Documentation https://www.terraform.io/docs/backends/types/index.html https://registry.terraform.io/search?q=state","title":"Lesson 107"},{"location":"lesson7/#lesson-7-state","text":"After starting a project getting Access to a Cloud account/project, creating a state bucket is step 2. This is usually an S3 bucket, Cloud storage, Blob Storage or Terraform Cloud Workspace. Having a remotely managed state file allows you to cooperate on using and creating infrastructure code. A statefiles' location is determined when you invoke Terraform init. --","title":"Lesson 7 State"},{"location":"lesson7/#local-state","text":"When you first start and apply your template, a state file is left behind. { \"version\" : 4 , \"terraform_version\" : \"0.12.20\" , \"serial\" : 9 , \"lineage\" : \"c430de7f-a3f5-e2d1-f912-0beb92340157\" , \"outputs\" : {}, \"resources\" : [ { \"mode\" : \"data\" , \"type\" : \"archive_file\" , \"name\" : \"hello-world\" , \"provider\" : \"provider.archive\" , \"instances\" : [ { \"schema_version\" : 0 , \"attributes\" : { \"excludes\" : null , \"id\" : \"57f31171437c7fb9dde5382167d421d966eb0707\" , \"output_base64sha256\" : \"rna/NuWSsy6/EZaDG7bGpz1rfX1bawF3OAKjyjBc/i8=\" , \"output_md5\" : \"5ddf9823dd4e8dbf3c0d8c2e642a2a05\" , \"output_path\" : \"./lambda.zip\" , \"output_sha\" : \"57f31171437c7fb9dde5382167d421d966eb0707\" , \"output_size\" : 262 , \"source\" : [], \"source_content\" : null , \"source_content_filename\" : null , \"source_dir\" : null , \"source_file\" : \"./code/lambda.py\" , \"type\" : \"zip\" } } ] }, { \"mode\" : \"data\" , \"type\" : \"aws_iam_role\" , \"name\" : \"basic\" , \"provider\" : \"provider.aws\" , \"instances\" : [ { \"schema_version\" : 0 , \"attributes\" : { \"arn\" : \"arn:aws:iam::680235478471:role/lambda_basic_execution\" , \"assume_role_policy\" : \"{\\\"Version\\\":\\\"2012-10-17\\\",\\\"Statement\\\":[{\\\"Effect\\\":\\\"Allow\\\",\\\"Principal\\\":{\\\"Service\\\":\\\"lambda.amazonaws.com\\\"},\\\"Action\\\":\\\"sts:AssumeRole\\\"}]}\" , \"assume_role_policy_document\" : null , \"create_date\" : \"2016-10-04T13:19:01Z\" , \"description\" : \"\" , \"id\" : \"lambda_basic_execution\" , \"max_session_duration\" : 3600 , \"name\" : \"lambda_basic_execution\" , \"path\" : \"/\" , \"permissions_boundary\" : \"\" , \"role_id\" : null , \"role_name\" : null , \"unique_id\" : \"AROAJLLUCPL4OFV5WAGMM\" } } ] }, { \"mode\" : \"managed\" , \"type\" : \"aws_lambda_function\" , \"name\" : \"hello_world\" , \"provider\" : \"provider.aws\" , \"instances\" : [ { \"schema_version\" : 0 , \"attributes\" : { \"arn\" : \"arn:aws:lambda:us-west-2:680235478471:function:hello-world\" , \"dead_letter_config\" : [], \"description\" : \"\" , \"environment\" : [], \"filename\" : \"./lambda.zip\" , \"function_name\" : \"hello-world\" , \"handler\" : \"lambda.lambda_handler\" , \"id\" : \"hello-world\" , \"invoke_arn\" : \"arn:aws:apigateway:us-west-2:lambda:path/2015-03-31/functions/arn:aws:lambda:us-west-2:680235478471:function:hello-world/invocations\" , \"kms_key_arn\" : \"\" , \"last_modified\" : \"2020-02-22T18:15:37.396+0000\" , \"layers\" : null , \"memory_size\" : 128 , \"publish\" : false , \"qualified_arn\" : \"arn:aws:lambda:us-west-2:680235478471:function:hello-world:$LATEST\" , \"reserved_concurrent_executions\" : -1 , \"role\" : \"arn:aws:iam::680235478471:role/lambda_basic_execution\" , \"runtime\" : \"python3.7\" , \"s3_bucket\" : null , \"s3_key\" : null , \"s3_object_version\" : null , \"source_code_hash\" : \"rna/NuWSsy6/EZaDG7bGpz1rfX1bawF3OAKjyjBc/i8=\" , \"source_code_size\" : 262 , \"tags\" : null , \"timeout\" : 3 , \"timeouts\" : null , \"tracing_config\" : [ { \"mode\" : \"PassThrough\" } ], \"version\" : \"$LATEST\" , \"vpc_config\" : [] }, \"private\" : \"eyJlMmJmYjczMC1lY2FhLTExZTYtOGY4OC0zNDM2M2JjN2M0YzAiOnsiY3JlYXRlIjo2MDAwMDAwMDAwMDB9fQ==\" } ] } ] } It holds a record of what happened. If you plan to persist what you make, or have more than 1 user, remote state is a must. Do not check in Terraform.tfstate , EVER, as it can contain secrets.","title":"Local State"},{"location":"lesson7/#remote-state","text":"So just about every project should use remote state to secure it's work. To use remote state, a remote state bucket reference is required. To use an S3 bucket, you have a similar section as below in your terraform.tf : terraform { backend \"s3\" { bucket = \"allthestates\" key = \"phrasing/terraform.tfstate\" region = \"eu-west-1\" } } For state buckets the following are critically important: Locking. Considering a locking DynamoDB table early. It's a private bucket. Encryption. It can contain secrets Do not edit manually. Plan to run your Terraform regularly as part of a configuration management process. A State Bucket per AWS account/GCP project/Azure Subscription. S3 versioning. A Statefile per template. And make sure you have unique statefiles. If you use the same statefile in 2 templates what will happen? Try 2 different statefiles from the same template.","title":"Remote state"},{"location":"lesson7/#reading-remote-state","text":"A one point there was pretty much only one way of finding out what happened in another template, the remote state datasource in Terraform: data \"terraform_remote_state\" \"network\" { backend = \"s3\" config = { bucket = \"allthestates\" key = \"phrasing/terraform.tfstate\" region = \"eu-west-1\" } } This allows you to read the output, if any, of the state file of another template, if permitted. That Datasource used to be the only way of the finding out results of other runs. There are now almost as many Datasource objects as resources, so you don't have to know it's location, which makes for looser coupling. This also allows you to conditionally create or read objects in Terraform. You might still need this, but it's probably a code smell.","title":"Reading remote state"},{"location":"lesson7/#importing","text":"Most resources support Terraform import statement this allows you to import existing resource into Terraform as if you'd created them.","title":"Importing"},{"location":"lesson7/#refactor","text":"Using the lessons from earlier refactor this chapter. Takeaways Always use remote state Locking never checkin, update your, .gitignore with an exclusion.","title":"Refactor"},{"location":"lesson7/#exercises","text":"Create a statebucket with Terraform. Migrate to remote state for the lambda template with created in step 4. Create an example to use conditional creation of resources. What could go wrong? How do you manage locking on an S3 bucket? A colleague created S3 bucket via the console, but it should have been done via Terraform, it can't be deleted, how do I turn this into a managed resource?","title":"Exercises"},{"location":"lesson7/#questions","text":"Why might using conditional creation using datasources be a bad idea? What will happen if you share statefiles across templates? What is drift?","title":"Questions"},{"location":"lesson7/#documentation","text":"https://www.terraform.io/docs/backends/types/index.html https://registry.terraform.io/search?q=state","title":"Documentation"},{"location":"lesson8/","text":"Lesson 201 Repository Patterns How should my Infra code be structured In Git permissions, access, branching and PRS are set-up on a repository basis. What can you reasonable manage as an owner/contributor should shape the structure. What is a \"manageable piece of infrastructure\"? There is no one answer, it depends on the project aims and the situation you start in. Your IAC will use a combination of these approaches.ld Each folder should be directly run-able by Terraform: environment\\eu-west-1\\test$ terraform apply ... Branching Code submitted to master via PRS on very short lived feature branches, or trunk based development. Don't branch by environment. Branching with state references is difficult/hazardous. Landing Zone Pattern When to use: To set up an account for use by applications, to control account level resources e.g. VPC, security. \u2514\u2500\u2500\u2500environments \u2514\u2500\u2500\u2500eu-west-1 \u251c\u2500\u2500\u2500dev \u2514\u2500\u2500\u2500test main.auto.tfvars main.tf Makefile outputs.tf provider.aws.tf README.md variables.tf Pros One project to rule them all. Simple in design. Cons Slow to apply, update, some account level infra is very slow to create, change or destroy. Partial destroying of an account is risky. Whole account apply is risky, unless you plan first. Destroying whole environments at this level can often make little sense. Harder for multiple people to work on at once Lack of isolation, 2 or more developers working on same environment. Not simple in practice. Ops like. Very Controlling. It's not really CI if you have a confirm an apply. For many account level objects destroying them, rarely practical makes sense (AD, IAM, AD, Cloudtrail and other Security related resources) Nuclear level blast radius. Note Should never contain module code. Separation Pattern When to use: Some objects are neither the landing Zone nor a single services application code. Each environment/workspace has a build process and life-cycle. \u251c\u2500\u2500\u2500eks \u2502 \u2514\u2500\u2500\u2500eu-west-1 \u2502 \u251c\u2500\u2500\u2500dev <eks-region-dev> \u2502 \u2502 main.auto.tfvars \u2502 \u2502 main.tf \u2502 \u2502 Makefile \u2502 \u2502 outputs.tf \u2502 \u2502 provider.aws.tf \u2502 \u2502 README.md \u2502 \u2502 variables.tf \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500test <eks-region-test> \u2514\u2500\u2500\u2500elasticsearch \u2514\u2500\u2500\u2500eu-west-1 \u251c\u2500\u2500\u2500dev <elasticsearch-region-dev> \u2502 main.auto.tfvars \u2502 main.tf \u2502 Makefile \u2502 outputs.tf \u2502 provider.aws.tf \u2502 README.md \u2502 variables.tf \u2502 \u2514\u2500\u2500\u2500test <elasticsearch-region-test> Pros Change is isolated Blast radius limited Cons Requires Invocation of multiple workspaces to make an environment. Duplication of properties. Note Should never contain module code. Workspace Builds can be chained. Application Pattern When to use: For development teams to manage their own applications infrastructure, infrastructure code lives alongside application code. In DevOps, we empower development teams, so for dev teams to modify and manage. It could be Terraform, Pulumi https://www.pulumi.com/ , Serverless https://serverless.com/https://serverless.com/ or SAM https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/what-is-sam.html the structure should still be something like: \u251c\u2500\u2500\u2500iac \u2502 \u251c\u2500\u2500\u2500lambda \u2502 \u2502 \u251c\u2500\u2500\u2500dev \u2502 \u2502 \u2502 main.auto.tfvars \u2502 \u2502 \u2502 main.tf \u2502 \u2502 \u2502 Makefile \u2502 \u2502 \u2502 outputs.tf \u2502 \u2502 \u2502 provider.aws.tf \u2502 \u2502 \u2502 README.md \u2502 \u2502 \u2502 variables.tf \u2502 \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500test \u2502 \u2514\u2500\u2500\u2500service \u2502 \u251c\u2500\u2500\u2500dev \u2502 \u2502 main.auto.tfvars \u2502 \u2502 main.tf \u2502 \u2502 Makefile \u2502 \u2502 outputs.tf \u2502 \u2502 provider.aws.tf \u2502 \u2502 README.md \u2502 \u2502 variables.tf \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500test \u2514\u2500\u2500\u2500src Pros Run infra provisioning as part of your deployment process. Isolated changes. Access control. Cons Duplication of properties across multi application Note Should never contain module code. Module Pattern When to use: Once you've created a reusable module, it should reside in a separate repository, so that it is a manageable and reusable component with ots own life-cycle. A module should always contain an example implementation and documentation. Repositories are named after their purpose and technology terraform-<PROVIDER>-<NAME> . Versioning uses the Semantic scheme. Below is the layout for a module for activemq \u2514\u2500\u2500\u2500terraform-aws-activemq \u2502 .gitattributes \u2502 .gitignore \u2502 .markdownlint.json \u2502 .markdownlintrc \u2502 .pre-commit-config.yaml \u2502 .terraformignore \u2502 aws_mq_broker.broker.tf \u2502 aws_mq_configuration.broker.tf \u2502 aws_security_group.broker.tf \u2502 LICENSE \u2502 main.tf \u2502 outputs.tf \u2502 password.tf \u2502 README.md \u2502 validate.ps1 \u2502 validate.sh \u2502 variables.tf \u2502 \u251c\u2500\u2500\u2500.chglog \u2502 CHANGELOG.tpl.md \u2502 config.yml \u2502 \u251c\u2500\u2500\u2500.dependabot \u2502 config.yml \u2502 \u251c\u2500\u2500\u2500.github \u2502 \u2514\u2500\u2500\u2500workflows \u2502 main.yml \u2502 \u2514\u2500\u2500\u2500example \u2514\u2500\u2500\u2500examplea data.network.tf examplea.auto.tfvars Makefile module.broker.tf outputs.tf provider.aws.tf variables.tf Cons None Pros Simple. Module has own life-cycle, versioning and testing process. Re-use by design. Allows you to fix module versions across environments and promote a module through an applications stages. Refactor Takeaways take this Exercises Questions Documentation https://www.terraform.io/docs/registry/modules/publish.html","title":"Lesson 201"},{"location":"lesson8/#lesson-201-repository-patterns","text":"","title":"Lesson 201 Repository Patterns"},{"location":"lesson8/#how-should-my-infra-code-be-structured","text":"In Git permissions, access, branching and PRS are set-up on a repository basis. What can you reasonable manage as an owner/contributor should shape the structure. What is a \"manageable piece of infrastructure\"? There is no one answer, it depends on the project aims and the situation you start in. Your IAC will use a combination of these approaches.ld Each folder should be directly run-able by Terraform: environment\\eu-west-1\\test$ terraform apply ...","title":"How should my Infra code be structured"},{"location":"lesson8/#branching","text":"Code submitted to master via PRS on very short lived feature branches, or trunk based development. Don't branch by environment. Branching with state references is difficult/hazardous.","title":"Branching"},{"location":"lesson8/#landing-zone-pattern","text":"When to use: To set up an account for use by applications, to control account level resources e.g. VPC, security. \u2514\u2500\u2500\u2500environments \u2514\u2500\u2500\u2500eu-west-1 \u251c\u2500\u2500\u2500dev \u2514\u2500\u2500\u2500test main.auto.tfvars main.tf Makefile outputs.tf provider.aws.tf README.md variables.tf","title":"Landing Zone Pattern"},{"location":"lesson8/#pros","text":"One project to rule them all. Simple in design.","title":"Pros"},{"location":"lesson8/#cons","text":"Slow to apply, update, some account level infra is very slow to create, change or destroy. Partial destroying of an account is risky. Whole account apply is risky, unless you plan first. Destroying whole environments at this level can often make little sense. Harder for multiple people to work on at once Lack of isolation, 2 or more developers working on same environment. Not simple in practice. Ops like. Very Controlling. It's not really CI if you have a confirm an apply. For many account level objects destroying them, rarely practical makes sense (AD, IAM, AD, Cloudtrail and other Security related resources) Nuclear level blast radius. Note Should never contain module code.","title":"Cons"},{"location":"lesson8/#separation-pattern","text":"When to use: Some objects are neither the landing Zone nor a single services application code. Each environment/workspace has a build process and life-cycle. \u251c\u2500\u2500\u2500eks \u2502 \u2514\u2500\u2500\u2500eu-west-1 \u2502 \u251c\u2500\u2500\u2500dev <eks-region-dev> \u2502 \u2502 main.auto.tfvars \u2502 \u2502 main.tf \u2502 \u2502 Makefile \u2502 \u2502 outputs.tf \u2502 \u2502 provider.aws.tf \u2502 \u2502 README.md \u2502 \u2502 variables.tf \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500test <eks-region-test> \u2514\u2500\u2500\u2500elasticsearch \u2514\u2500\u2500\u2500eu-west-1 \u251c\u2500\u2500\u2500dev <elasticsearch-region-dev> \u2502 main.auto.tfvars \u2502 main.tf \u2502 Makefile \u2502 outputs.tf \u2502 provider.aws.tf \u2502 README.md \u2502 variables.tf \u2502 \u2514\u2500\u2500\u2500test <elasticsearch-region-test>","title":"Separation Pattern"},{"location":"lesson8/#pros_1","text":"Change is isolated Blast radius limited","title":"Pros"},{"location":"lesson8/#cons_1","text":"Requires Invocation of multiple workspaces to make an environment. Duplication of properties. Note Should never contain module code. Workspace Builds can be chained.","title":"Cons"},{"location":"lesson8/#application-pattern","text":"When to use: For development teams to manage their own applications infrastructure, infrastructure code lives alongside application code. In DevOps, we empower development teams, so for dev teams to modify and manage. It could be Terraform, Pulumi https://www.pulumi.com/ , Serverless https://serverless.com/https://serverless.com/ or SAM https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/what-is-sam.html the structure should still be something like: \u251c\u2500\u2500\u2500iac \u2502 \u251c\u2500\u2500\u2500lambda \u2502 \u2502 \u251c\u2500\u2500\u2500dev \u2502 \u2502 \u2502 main.auto.tfvars \u2502 \u2502 \u2502 main.tf \u2502 \u2502 \u2502 Makefile \u2502 \u2502 \u2502 outputs.tf \u2502 \u2502 \u2502 provider.aws.tf \u2502 \u2502 \u2502 README.md \u2502 \u2502 \u2502 variables.tf \u2502 \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500test \u2502 \u2514\u2500\u2500\u2500service \u2502 \u251c\u2500\u2500\u2500dev \u2502 \u2502 main.auto.tfvars \u2502 \u2502 main.tf \u2502 \u2502 Makefile \u2502 \u2502 outputs.tf \u2502 \u2502 provider.aws.tf \u2502 \u2502 README.md \u2502 \u2502 variables.tf \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500test \u2514\u2500\u2500\u2500src","title":"Application Pattern"},{"location":"lesson8/#pros_2","text":"Run infra provisioning as part of your deployment process. Isolated changes. Access control.","title":"Pros"},{"location":"lesson8/#cons_2","text":"Duplication of properties across multi application Note Should never contain module code.","title":"Cons"},{"location":"lesson8/#module-pattern","text":"When to use: Once you've created a reusable module, it should reside in a separate repository, so that it is a manageable and reusable component with ots own life-cycle. A module should always contain an example implementation and documentation. Repositories are named after their purpose and technology terraform-<PROVIDER>-<NAME> . Versioning uses the Semantic scheme. Below is the layout for a module for activemq \u2514\u2500\u2500\u2500terraform-aws-activemq \u2502 .gitattributes \u2502 .gitignore \u2502 .markdownlint.json \u2502 .markdownlintrc \u2502 .pre-commit-config.yaml \u2502 .terraformignore \u2502 aws_mq_broker.broker.tf \u2502 aws_mq_configuration.broker.tf \u2502 aws_security_group.broker.tf \u2502 LICENSE \u2502 main.tf \u2502 outputs.tf \u2502 password.tf \u2502 README.md \u2502 validate.ps1 \u2502 validate.sh \u2502 variables.tf \u2502 \u251c\u2500\u2500\u2500.chglog \u2502 CHANGELOG.tpl.md \u2502 config.yml \u2502 \u251c\u2500\u2500\u2500.dependabot \u2502 config.yml \u2502 \u251c\u2500\u2500\u2500.github \u2502 \u2514\u2500\u2500\u2500workflows \u2502 main.yml \u2502 \u2514\u2500\u2500\u2500example \u2514\u2500\u2500\u2500examplea data.network.tf examplea.auto.tfvars Makefile module.broker.tf outputs.tf provider.aws.tf variables.tf","title":"Module Pattern"},{"location":"lesson8/#cons_3","text":"None","title":"Cons"},{"location":"lesson8/#pros_3","text":"Simple. Module has own life-cycle, versioning and testing process. Re-use by design. Allows you to fix module versions across environments and promote a module through an applications stages.","title":"Pros"},{"location":"lesson8/#refactor","text":"Takeaways take this","title":"Refactor"},{"location":"lesson8/#exercises","text":"","title":"Exercises"},{"location":"lesson8/#questions","text":"","title":"Questions"},{"location":"lesson8/#documentation","text":"https://www.terraform.io/docs/registry/modules/publish.html","title":"Documentation"},{"location":"lesson9/","text":"Lesson 8 Refactor Using the lessons from earlier refactor this chapter. Takeaways take this Exercises Questions Documentation","title":"Lesson 202"},{"location":"lesson9/#lesson-8","text":"","title":"Lesson 8"},{"location":"lesson9/#refactor","text":"Using the lessons from earlier refactor this chapter. Takeaways take this","title":"Refactor"},{"location":"lesson9/#exercises","text":"","title":"Exercises"},{"location":"lesson9/#questions","text":"","title":"Questions"},{"location":"lesson9/#documentation","text":"","title":"Documentation"}]}